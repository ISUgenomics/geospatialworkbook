{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2da25b6f-d5bb-4cec-9a26-563588dbef59",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## The Raster Vision Pipeline\n",
    "\n",
    "##### \"Raster Vision is an open source library and framework for Python developers building computer vision models on satellite, aerial, and other large imagery sets (including oblique drone imagery). There is built-in support for chip classification, object detection, and semantic segmentation using PyTorch.\" [(rastervision.io)](https://rastervision.io/) </br>\n",
    "Raster Vision, a geospatial software tool produced by the company [Azavea](https://www.azavea.com/), can be used as either a framework or as a library. The Raster Vision framework abstracts away many technical details of geospatial deep learning, and allows users to customize and run a deep learning pipeline. Advanced python programmers can use the Raster Vision library to use pieces of Raster Vision code in their own projects. We will focus solely on how to use the Raster Vision framework in this tutorial. </br></br>\n",
    "Raster Vision is built on pytorch, which is a popular python library used for building and training neural networks. The Raster Vision framework utilizes a pipeline of execution that performs a series of steps to prepare the data, train the model, use the model to predict on the validation set, calculate evaluation metrics, and bundle the model for deployment. </br>\n",
    "\n",
    "![RV pipeline](https://docs.rastervision.io/en/0.21/_images/rv-pipeline-overview.png) \n",
    "###### [Raster Vision Pipeline Image Source](https://docs.rastervision.io/en/0.21/framework/pipelines.html)</br>\n",
    "\n",
    "Raster Vision is a low-code platform. Users will still need to write python code to specify how they want to build their model, however they will need to write much less code than if they were building the same model from scratch in pytorch. For example, users will not have to write code to chip the data or perform the training loop, but they will need to specify the chip size, the method for constructing chips, what model architecture to use, and which of the three supported Deep Learning tasks to perform (chip classification, object detection, or semantic segmentation). </br></br>\n",
    "\n",
    "Raster Vision is ideal for researchers who:\n",
    "* Have large, fully labelled geospatial datasets they wish to expand to cover additional sites\n",
    "    * Ex: satellite imagery, and associated vector data outlining objects of interest for Object Detection\n",
    "    * Ex: aerial drone imagery, and associated raster data representing segmentation masks for Semantic Segmentation\n",
    "* Can run their code on Atlas to take advantage of GPU acceleration\n",
    "* Have python experience\n",
    "\n",
    "##### Note: Raster Vision is not backwards compatible. When reading through documentation, ensure you are looking at the right version of Raster Vision. This tutorial is based on version 0.21.\n",
    "Some older versions of documentation do not contain the most up-to-date versions of Raster Vision, and will not list version 0.21 as an option. The most up-to-date documentation can be found at [rastervision.io](https://rastervision.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecc27e6-556a-44c2-a426-fcd6ac56c971",
   "metadata": {},
   "source": [
    "# Semantic Segmentation of Aerial Imagery with Raster Vision \n",
    "## Part 3: Constructing and Exploring the Singularity Image\n",
    "\n",
    "This tutorial series walks through an example of using [Raster Vision](https://rastervision.io/) to train a deep learning model to identify buildings in satellite imagery.</br>\n",
    "\n",
    "*Primary Libraries and Tools*:\n",
    "\n",
    "|Name|Description|Link|\n",
    "|-|-|-|\n",
    "| `Raster Vision ` | Library and framework for geospatial semantic segmentation, object detection, and chip classification with python| https://rastervision.io/ |\n",
    "| `Singularity` | Containerization software that allows for transportable and reproducible software | https://docs.sylabs.io/guides/3.5/user-guide/introduction.html |\n",
    "| `pandas` | Dataframes and other datatypes for data analysis and manipulation | https://pandas.pydata.org/ |\n",
    "| `geopandas` | Extends datatypes used by pandas to allow spatial operations on geometric types | https://geopandas.org/en/stable/ |\n",
    "| `rioxarray` | Data structures and routines for working with gridded geospatial data | https://github.com/corteva/rioxarray |\n",
    "| `plotnine` | A plotting library for Python modeled after R's [ggplot2](https://ggplot2.tidyverse.org/) | https://plotnine.readthedocs.io/en/v0.12.3/ |\n",
    "| `pathlib` | A Python library for handling files and paths in the filesystem | https://docs.python.org/3/library/pathlib.html |\n",
    "\n",
    "*Prerequisites*:\n",
    "  * Basic understanding of navigating the Linux command line, including navigating among directories and editing text files\n",
    "  * Basic python skills, including an understanding of object-oriented programming, function calls, and basic data types\n",
    "  * Basic understanding of shell scripts and job scheduling with SLURM for running code on Atlas\n",
    "  * A SCINet account for running this tutorial on Atlas\n",
    "  * **Completion of tutorial parts 1 and 2 of this series**\n",
    "\n",
    "*Tutorials in this Series*:\n",
    "  * 1\\. **Tutorial Setup on SCINet**\n",
    "  * 2\\. **Overview of Deep Learning for Imagery and the Raster Vision Pipeline**\n",
    "  * 3\\. **Constructing and Exploring the Singularity Image <span style=\"color: red;\">_(You are here)_</span>**\n",
    "  * 4\\. **Exploring the dataset and problem space**\n",
    "  * 5\\. **Overview of Raster Vision Model Configuration and Setup**\n",
    "  * 6\\. **Breakdown of Raster Vision Code Version 1**\n",
    "  * 7\\. **Evaluating training performance and visualizing predictions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae7461b-d220-443d-88c0-d36e1c8010a1",
   "metadata": {},
   "source": [
    "## Constructing and Exploring the Singularity Image\n",
    "#### Users who are not familiar with containerization are strongly encouraged to go through [this tutorial](https://carpentries-incubator.github.io/singularity-introduction/). </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed30fa7d-e432-478d-ab4f-5ba91cca6668",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1. Containerization Background and Setup\n",
    "One of the most difficult aspects of software development is setting up the computing environment - ensuring you are running your code with all the right software configurations set and dependency versions installed. You may build an application on your machine, but struggle to get it to work the same way on a different machine because of differing software installations and configurations. Containerization is used to prevent dependency issues and improve the portability of code. Containers are collections of code along with all the needed libraries and dependencies that can be easily moved from one machine to another. Since all the correct versions of all the dependencies are included in the container, users won't run into issues of needing different versions of a dependency for different applications. Docker and Singularity are two different containerization platforms, each with their own pros and cons. </br>\n",
    "\n",
    "##### Terminology note: an *image* is a snapshot of a computing environment, like a blueprint for a container. A *container* is an isolated computing environment built from the instructions in the image. Containers are running instances of images.</br>\n",
    "\n",
    "The developers of Raster Vision publish the Raster Vision software as Docker images to simplify the process of running the Raster Vision pipeline. New versions of Raster Vision are released as Docker images [here](https://quay.io/repository/azavea/raster-vision?tab=tags). Docker is a popular containerization tool, however it requires root access and therefore can't be used on an HPC. Singularity, on the other hand, can be used on an HPC, so in the following instructions, we will build a singularity image out of Raster Vision's docker image so we can run Raster Vision on Atlas. </br></br>\n",
    "First, ensure that the variables `$project_dir` and `$project_name` are available. If you have started a new Jupyter session since creating these variables, then you will need to create them again. Check to see if they are available by running:</br>\n",
    "`echo $project_dir`</br>\n",
    "`echo $project_name`</br>\n",
    "##### If the project directory and project name do not appear, then return to the tutorial setup instructions [here](#var_setup) to create these variables before proceeding. </br>\n",
    "By default, singularity will cache all downloaded images to `$HOME/.singularity` so if the user deletes an image and attempts to re-download the same version, the image will be pulled from the local cache instead of a remote repository. This is a useful feature to decrease network demand, however Atlas users have limited space in their home directories, and the singularity cache can quickly fill up the limited space. The SCINet office recommends configuring the cache directory as follows to avoid filling up your home directory:</br></br>\n",
    "`export SINGULARITY_CACHEDIR=$TMPDIR`</br>\n",
    "`export SINGULARITY_TMPDIR=$TMPDIR`</br></br>\n",
    "Next, we will navigate to the project directory and run a script to pull a Raster Vision image from the remote repository. Note that this will take a while to run, so we recommend continuing with the following reading while this code runs. </br></br>\n",
    "`cd ${project_dir}/model` </br>\n",
    "`sbatch --account=$project_name make_singularity_img.sh` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00291a27-e8b9-4d01-8821-6c1ec31f8885",
   "metadata": {},
   "source": [
    "### 2. Singularity File Systems\n",
    "In addition to providing an isolated computing environment, singularity containers also have their own file systems separate from the host system's file system. Directories in the host system are made available within the container's file system by _binding_ directories. For example, say you have a directory of data files on the host file system at `/project/example/data` that you would like to have access to within the container. You could make this directory available within the container by binding the directory `/project/example/data` to a directory in the container's file system, such as `/opt/data`. Then, when you start the container, you can navigate to `/opt/data` within the container and access the files in `/project/example/data` on the host system. If you modify files in the container in `/opt/data`, then these changes will also affect the host system at `/project/example/data`. This way, we can save files to the host system from within the container to access later. Note that the permissions you have on the host system will be identical to the permissions you have within the container, so you can't perform any actions to the host's file system within a container that you couldn't otherwise do outside of the container.</br></br>\n",
    "Depending on the administrative configurations of the host system, certain directories in the host's file system are bound to directories in the container's file system by default. For example, it is common for the directory `$HOME` in the host's file system to be bound to the directory `/home` within the container. If you wish to bind additional directories, you can specify the directories you'd like to bind when you launch the container. We will discuss the specifics of how to bind directories later in section 3.4 after we discuss how to launch a container."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9464df5-be29-4e31-9000-393ecc86a583",
   "metadata": {},
   "source": [
    "### 3. Launching a Singularity Container\n",
    "There are several singularity commands that can be used to launch a singularity container from a singularity image file (.sif file). The most common commands to launch a container are `shell`, `run`, and `exec`. Here is a quick overview of these three commands: </br>\n",
    "\n",
    "`singularity shell my_image.sif` will build the container and launch an interactive shell environment in the container. This is useful for exploring the container interactively, and for debugging. You can shut down the container with the `exit` command. We will use this command soon to explore the raster vision container.</br></br>\n",
    "`singularity run my_image.sif` will run the default _runscript_ within the my_image container. A _runscript_ is including within a singularity image to specify the default behavior or what happens when we \"run\" a container. </br></br>\n",
    "`singularity exec my_image.sif command` allows us to run a command within the container, instead of the default behavior described in the runscript. This allows us to specify a different script within the container to run. For example, `singularity exec my_image.sif python python_script.py` will execute the `python_script.py` within the container. </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad6dd49-bb96-4c5a-9df4-17c320e2b685",
   "metadata": {},
   "source": [
    "### 4. Exploring the Raster Vision Container\n",
    "\n",
    "Once the `make_singularity_img.sh` script has completed running, you should see the file `raster-vision_pytorch-0.21.sif` in your project directory. First we will explore the container as is, then we will bind a directory of data files and ensure we can access them within the container. From your project directory, run the command: </br>\n",
    "`singularity shell raster-vision_pytorch-0.21.sif` </br></br>\n",
    "The container will take a minute to launch. Once it does, you will see your prompt changes to `Singularity >`. Next, run the commands: </br>\n",
    "`pwd` </br>\n",
    "`ls` </br></br>\n",
    "You will see the project directory that you launched the singularity container from. This directory is bound to the container by default, and the path to the project directory within the container is the same as the path to the project directory on the host system. Next, run the commands: </br>\n",
    "`cd /opt/src` </br>\n",
    "`ls` </br></br>\n",
    "Here we have the directory for the rastervision files within the container. Next we will launch the container with our data directory bound to the container. To exit the container, run the command:</br>\n",
    "`exit`</br></br>\n",
    "To bind a directory to the container, we use the option `-B` or `--bind`, followed by our binding specifications in the format `/host/system/directory/:/container/directory/`. Run the following command to launch the container with the `input` directory on the host system bound to `/opt/data` in the container. Here, `input` is a symbolic link to a directory to the `input` directory stored at `/reference/workshops/rastervision/input`. Note that if the directory we specify does not already exist in the container, it will be created. </br>\n",
    "``singularity shell -B `pwd`:/opt/data raster-vision_pytorch-0.21.sif`` </br>\n",
    "`cd /opt/data/input` </br>\n",
    "`ls` </br></br>\n",
    "Now we can see that our data is available within our container! When we run Raster Vision, we will bind our input and output directories so the Raster Vision pipeline can access our input data, and the pipeline can store output files in a directory on the host system. This way, we can see our model output files after the container is shut down."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
